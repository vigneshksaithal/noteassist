import { z } from 'zod';

/**
 * The operating system Highlight is running on.
 */
type Platform = 'darwin' | 'win32';
interface DesktopWindow {
    title: string;
    rawContents: string;
    url?: string;
    domain?: string;
    selectedText?: string;
}
/**
 * A third party application running on the user's computer.
 */
interface DesktopApplication {
    name: string;
    focusedWindow: DesktopWindow;
    appIcon?: string;
}
/**
 * Details about the Highlight app environment, like the version.
 */
interface HighlightEnvironment {
    /**
     * The version of Highlight the user is using
     */
    version: string;
    requestType?: string;
}
/**
 * Details about the environment that the user is currently in, such as the operating system.
 */
interface DesktopEnvironment {
    platform: Platform;
    /**
     * The scanned OCR contents of the user's entire screen.
     */
    ocrScreenContents?: string;
    screenshotPath?: string;
    clipboardText?: string;
    highlight?: HighlightEnvironment;
    screenshotBase64?: string;
}
/**
 * A more modern context object that seperates the foregrounded application
 * and the environment in which Highlight is running.
 */
interface HighlightContext {
    application: DesktopApplication;
    environment: DesktopEnvironment;
    /**
     * A string that represents the user's intent with the context of the application.
     */
    userIntent?: string;
    /**
     * The suggestion the user selected from the suggestions list.
     */
    suggestion?: string;
    attachments?: Attachment[];
}
interface FocusedWindow {
    appName: string;
    windowTitle: string;
    pid: number;
    isBlacklisted: boolean;
    url?: string;
}
/**
 * An item the user has elected to attach to provide additional context about their query.
 */
interface Attachment {
    type: 'audio' | 'clipboard' | 'screenshot' | 'file';
    value: string;
    mimeType?: string;
    fileName?: string;
}
/**
 * A message to be sent to an LLM through a chat like interface.
 */
interface LLMMessage {
    content: string;
    role: 'system' | 'user' | 'assistant';
}
type ChatOpenAIParams = {
    temperature?: number;
    topP?: number;
    frequencyPenalty?: number;
    presencePenalty?: number;
    n?: number;
    logitBias?: Record<string, number>;
    stop?: string[];
    stopSequences?: string[];
    maxTokens?: number;
    logprobs?: boolean;
    topLogprobs?: number;
};
/**
 * Events that Highlight developers may subscribe to.
 * Some events are used internally by the app-runtime library and may not be documented on the Highlight API docs.
 */
type HighlightEvent = 'onContext' | 'onTextPredictionUpdate' | 'onTextPredictionDone' | 'onConversationAttachment' | 'onAudioPermissionUpdate' | 'onAuthUpdate' | 'onPeriodicForegroundAppCheck' | 'onOpen' | 'onExternalMessage';
interface NavigateOptions {
    route: string;
}
interface OpenModalOptions {
    id: string;
    context?: Record<string, any>;
}
interface AppOpenEventOptions {
    isActiveApp?: boolean;
    action?: {
        type: 'navigate' | 'openModal';
        options: NavigateOptions | OpenModalOptions;
    };
}

/**
 * The entire exported Highlight API, available within your Highlight app.
 */
interface HighlightAPI {
    /**
     * A secure store for your app to save data.
     */
    appStorage: {
        isHydrated: () => boolean;
        whenHydrated: () => Promise<boolean>;
        all: () => Record<string, any>;
        get: (key: string) => any;
        set: (key: string, value: any) => void;
        setAll: (value: Record<string, any>) => void;
        delete: (key: string) => void;
        clear: () => void;
    };
    app: {
        /**
         * Check if the user has created a desktop shortcut for your app.
         * @param appSlug
         */
        hasDesktopShortcut: () => Promise<boolean>;
        /**
         * Prompt the user to create a desktop shortcut for your app.
         */
        requestCreateDesktopShortcut: () => Promise<void>;
        /**
         * Tell Highlight your app should run in the background.
         * If you don't have permission to run in the background, this will throw an error.
         * @see Highlight.permissions.requestBackgroundPermission
         */
        setBackgroundStatus: (status: boolean) => Promise<void>;
        /**
         * Show a notification to the user.
         * @param title The title of the notification.
         * @param body The body of the notification.
         */
        showNotification: (title: string, body: string) => void;
        /**
         * Get the hotkey the user should use to bring up the Highlight overlay window.
         * This is useful when onboarding users to show them how to activate your app.
         */
        getHotkey: () => Promise<string>;
        /**
         * Adds an event listener for your Highlight app.
         * @param event The name of the event to listen for.
         * @param listener The listener Highlight will call when the event is emitted.
         * @returns A function to remove the listener when you are done with it
         */
        addListener: (event: HighlightEvent, listener: (...args: any[]) => void) => () => void;
        /**
         * Open a Highlight app
         * @param appId - The ID of the app to open
         * @returns A promise that resolves when the app is opened
         */
        openApp: (appId: string) => Promise<void>;
    };
    permissions: {
        /**
         * Request permission to run your app in the background when Highlight starts.
         */
        requestBackgroundPermission: () => Promise<boolean>;
        /**
         * Request permission to read the contents of the user's clipboard.
         */
        requestClipboardReadPermission: () => Promise<boolean>;
        /**
         * Request permission to capture screenshots of the user's displays and windows
         */
        requestScreenshotPermission: () => Promise<boolean>;
        /**
         * Request permission to capture the contents of the user's windows
         */
        requestWindowContextPermission: () => Promise<boolean>;
    };
    user: {
        /**
         * Get the facts the user has set for themselves. This could be "I only want concise responses", "my name is...", etc.
         */
        getFacts: () => Promise<string[]>;
        /**
         * Set the ASR to run in realtime (1.1 seconds). This will use about 10x more GPU processing than non realtime, so once you are finished needing realtime transcripton, you should also set this to false
         * @param {boolean} isActive
         */
        setAsrRealtime: (isActive: boolean) => void;
        /**
         * Get the audio captions from the user's device.
         * @param {boolean} longAudio - If you want to get the long audio captions. Fetch ASR text for the last 2 hours
         * @returns {string} - The audio captions.
         */
        getAudio: (longAudio: boolean) => Promise<string>;
        /**
         * Get the audio captions from the user's device for the specified duration.
         * @param {number} duration - The duration in seconds for which you want to get the audio captions.
         * @returns {string} - The audio captions.
         */
        getAudioForDuration: (duration: number) => Promise<string>;
        /**
         * Get the microphone activity as a number from 0-5. 0 means no audio, 5 means absolute loudest.
         * @param {number} lastNumMs - specifies the duration in milliseconds for which you want to calculate the average energy of the mic input.
         * @returns {number} - The microphone activity from 0-5.
         */
        getMicActivity: (lastNumMs: number) => Promise<number>;
        getScreenshot: () => Promise<string>;
        /**
         * Get an email address for the user, for privacy, this address will forward to the user's real email address.
         * @returns {string} - The email address.
         */
        getEmail: () => Promise<string>;
        /**
         * Fetches the context of the window (ignoring Highlight), the same as the eventListener "onContext".
         * May be polled for repeated updates.
         */
        getContext: (paneDetectionEnabled?: boolean) => Promise<HighlightContext>;
        /**
         * Get the contents of the clipboard.
         * @returns {{ type: 'image' | 'text'; value: string }} - The type and value of the contents of the clipboard
         */
        getClipboardContents: () => Promise<{
            type: 'image' | 'text';
            value: string;
        } | undefined>;
        /**
         * @returns {Array<{ thumbnail: string }>} - An array of base64 encoded screenshots of the user's displays.
         */
        getDisplayScreenshots: () => Promise<{
            thumbnail: string;
        }[]>;
        /**
         * Gets the titles and app icons of the user's open windows
         * @returns {Array<{ windowTitle: string; appIcon?: string }>} - An array of window titles and app icons.
         */
        getWindows: () => Promise<{
            windowTitle: string;
            appIcon?: string;
        }[]>;
        /**
         * Get a screenshot of a specific window.
         * @param {string} windowTitle - The title of the window to screenshot. This is the same as the window title you get from getWindows.
         * @returns {string} - Base64 encoded screenshot of the window.
         */
        getWindowScreenshot: (windowTitle: string) => Promise<string>;
        /**
         * Get the context of a specific window
         * @param {string} windowTitle - The title of the window to get the context of.
         * @returns {HighlightContext} - The context of the window.
         */
        getWindowContext: (windowTitle: string) => Promise<HighlightContext>;
    };
    vectorDB: {
        /**
         * Create a table in the vector database.
         * @param tableName
         * @returns
         */
        createTable: (tableName: string) => Promise<void>;
        /**
         * Insert an item into a table in the vector database.
         * @param tableName
         * @param text
         * @returns
         */
        insertItem: (tableName: string, text: string, metadata: object) => Promise<void>;
        /**
         * Get all items in a table in the vector database.
         * @param tableName
         * @returns
         */
        getAllItems: (tableName: string) => Promise<any[]>;
        /**
         * Update text for an item in a table in the vector database.
         * @param tableName
         * @param id
         * @param text
         * @param metadata
         * @returns
         */
        updateText: (tableName: string, id: string, text: string, metadata: object) => Promise<void>;
        /**
         * Update metadata for an item in a table in the vector database.
         * @param tableName
         * @param id
         * @param metadata
         * @returns
         */
        updateMetadata: (tableName: string, id: string, metadata: object) => Promise<void>;
        /**
         * Search for items in a table in the vector database.
         * @param tableName
         * @param text
         * @param maxResults
         * @returns
         */
        search: (tableName: string, text: string, maxResults: number) => Promise<any[]>;
        /**
         * Delete an item from a table in the vector database.
         * @param tableName
         * @param id
         * @returns
         */
        deleteItem: (tableName: string, id: string) => Promise<void>;
        /**
         * Delete a table from the vector database.
         * @param tableName
         * @returns
         */
        deleteTable: (tableName: string) => Promise<void>;
    };
    auth: {
        /**
         * Get an access token and refresh token that can be used to validate the user's session on your backend.
         */
        signIn: () => Promise<{
            accessToken: string;
            refreshToken: string;
        }>;
    };
    inference: {
        /**
         * @returns {boolean} - Whether the user's device is capable of running a Small Language Model.
         */
        isSlmCapable: () => Promise<boolean>;
        /**
         * Get a text prediction from a locally running Small Language Model(SLM).
         * @param messages The messages to send to the SLM.
         * @param grammar The grammar in GBNF format to send to the SLM.
         * @returns A text prediction.
         */
        getTextPredictionSlm: (messages: LLMMessage[], grammar?: string) => Promise<string>;
        /**
         * Get a stream of text predictions from an LLM.
         * @param messages The messages to send to the LLM.
         * @returns A stream of text predictions.
         */
        getTextPrediction: (messages: LLMMessage[], params?: ChatOpenAIParams) => AsyncGenerator<string>;
        /**
         * Get a stream of structured text predictions from an LLM.
         * @param structure The Zod structure the output should be in
         */
        getStructuredTextPrediction<T>(structure: z.ZodType<T>, messages: LLMMessage[], params?: ChatOpenAIParams): AsyncGenerator<T>;
    };
    /**
     * Adds an event listener for your Highlight app.
     * @param event The name of the event to listen for.
     * @param listener The listener Highlight will call when the event is emitted.
     * @deprecated use `Highlight.app.addListener` instead
     */
    addEventListener: (event: HighlightEvent, listener: (...args: any[]) => void) => void;
    /**
     * Removes an event listener that you previously registered.
     * @deprecated use `Highlight.app.addListener` instead, and call the return value to remove the listener
     */
    removeEventListener: (event: HighlightEvent, listener: (...args: any[]) => void) => void;
    /**
     * Adds an event listener for your Highlight app that will only fire once.
     * @deprecated use `Highlight.app.addListener` instead, and call the return value to remove the listener after you've used it
     */
    once: (event: HighlightEvent, listener: (...args: any[]) => void) => void;
    /**
     * Check if your app is running in Highlight.
     */
    isRunningInHighlight: () => boolean;
}
declare const api: HighlightAPI;

export { type AppOpenEventOptions, type Attachment, type ChatOpenAIParams, type DesktopApplication, type DesktopEnvironment, type DesktopWindow, type FocusedWindow, type HighlightAPI, type HighlightContext, type HighlightEnvironment, type HighlightEvent, type LLMMessage, type NavigateOptions, type OpenModalOptions, type Platform, api as default };
